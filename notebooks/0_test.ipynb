{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_html(url: str, filename: str) -> None:\n",
    "    \"\"\"\n",
    "    Saves the HTML content of a URL to a file under ../data directory.\n",
    "\n",
    "    Args:\n",
    "    url (str): The URL of the webpage to save.\n",
    "    filename (str): The name of the file to save the HTML content to.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Create the data directory if it doesn't exist\n",
    "    if not os.path.exists('../data'):\n",
    "        os.makedirs('../data')\n",
    "\n",
    "    # Get the HTML content of the URL\n",
    "    response = requests.get(url)\n",
    "    html_content = response.content\n",
    "\n",
    "    # Save the HTML content to a file\n",
    "    with open(f'../data/{filename}', 'wb') as f:\n",
    "        f.write(html_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(filename: str) -> list:\n",
    "    \"\"\"\n",
    "    Returns a list of all links in <a> tags in an HTML file.\n",
    "\n",
    "    Args:\n",
    "    filename (str): The name of the HTML file to parse.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of all links in <a> tags in the HTML file.\n",
    "    \"\"\"\n",
    "    # Open the HTML file and create a BeautifulSoup object\n",
    "    with open(filename, 'r', encoding=\"latin-1\") as f:\n",
    "        html_doc = f.read()\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "\n",
    "    # Find all <a> tags and extract the href attribute\n",
    "    links = []\n",
    "    for a_tag in soup.find_all('a'):\n",
    "        link = a_tag.get('href')\n",
    "        if link:\n",
    "            links.append(link)\n",
    "\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PageNode:\n",
    "    def __init__(self, name:str, page_from:set() = set(), page_to:set() = set()) -> None:\n",
    "        self._name = name\n",
    "        self._page_from = page_from\n",
    "        self._page_to = page_to\n",
    "\n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        return self._name\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return self.__repr__()\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return self._name\n",
    "    \n",
    "    def add_pages_to(self, pages:set()) -> None:\n",
    "        self._page_to.update(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"http://www.cibc.com\"\n",
    "initial_url = \"/en/personal-banking.html\"\n",
    "filter_str = \"/en/personal-banking\"\n",
    "#all_links = {\"_personal-banking.html\": {\"name\": \"/personal-banking.html\", \"scraped\": False, \"page_from\": set(), \"page_to\": set()}}\n",
    "graph = {initial_url : PageNode(initial_url)}\n",
    "to_visit = set({initial_url})\n",
    "visited = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"http://www.cibc.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "current = to_visit.pop()\n",
    "\n",
    "save_html(f'{prefix}{current}', current.replace('/', '_'))\n",
    "\n",
    "visited.add(current)\n",
    "\n",
    "page_links = get_links(f'../data/{current.replace(\"/\", \"_\")}')\n",
    "page_links = {link for link in page_links if filter_str in link}\n",
    "page_links = {link for link in page_links if link not in visited}\n",
    "page_links = {link for link in page_links if link not in to_visit}\n",
    "graph[current].add_pages_to(page_links)\n",
    "\n",
    "# find which files have been collected\n",
    "# collected_files = os.listdir('../data')\n",
    "# if current not in collected_files:\n",
    "#     save_html('/personal-banking.html', i)\n",
    "#     page_links = set(get_links(f'../data/{current}'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in graph[current]._page_to:\n",
    "    if i not in visited:\n",
    "        if i not in to_visit:\n",
    "            graph[i] = PageNode(i)\n",
    "            to_visit.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(to_visit), len(visited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(to_visit) > 0:\n",
    "    current = to_visit.pop()\n",
    "    print(\"Visiting:\", current)\n",
    "    tmp = \"\"\n",
    "    if not current.startswith(\"http\"):\n",
    "        tmp = prefix\n",
    "    save_html(tmp + current, current.replace('/', '_'))\n",
    "\n",
    "    visited.add(current)\n",
    "\n",
    "    page_links = get_links(f'../data/{current.replace(\"/\", \"_\")}')\n",
    "    page_links = {link for link in page_links if filter_str in link}\n",
    "    page_links = {link for link in page_links if link not in visited}\n",
    "    page_links = {link for link in page_links if link not in to_visit}\n",
    "    page_links = {link for link in page_links if link.endswith('.html')}\n",
    "    graph[current].add_pages_to(page_links)\n",
    "\n",
    "    for i in graph[current]._page_to:\n",
    "        if i not in visited:\n",
    "            if i not in to_visit:\n",
    "                graph[i] = PageNode(i)\n",
    "                to_visit.add(i)\n",
    "    \n",
    "    print(\"Number of pages to visit:\", len(to_visit), \"\\nNumber of Pages Visited:\", len(visited))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
